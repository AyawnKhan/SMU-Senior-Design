{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# FinQA — Hallucination Detection via Uncertainty Quantification\n",
    "**Part A | Owners: Ayan Khan & Anum Khan**\n",
    "\n",
    "This notebook walks through three UQ methods to detect hallucinations in financial reasoning:\n",
    "1. **Self-Consistency** — sample N answers, measure agreement\n",
    "2. **LogProb Entropy** — measure token-level uncertainty via logprobs\n",
    "3. **Verbalized Confidence** — ask the model to self-report confidence\n",
    "\n",
    "Then we check: *does high confidence actually correlate with correctness?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-setup-header",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface_hub>=0.24.5 in /Users/anumkhan/venv/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: filelock>=3.10.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (4.67.3)\n",
      "Requirement already satisfied: typer in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (0.23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from huggingface_hub>=0.24.5) (4.15.0)\n",
      "Requirement already satisfied: anyio in /Users/anumkhan/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/anumkhan/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (2026.2.25)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/anumkhan/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/anumkhan/venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/anumkhan/venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/anumkhan/venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub>=0.24.5) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from typer->huggingface_hub>=0.24.5) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from typer->huggingface_hub>=0.24.5) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from typer->huggingface_hub>=0.24.5) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/anumkhan/venv/lib/python3.9/site-packages (from typer->huggingface_hub>=0.24.5) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from rich>=12.3.0->typer->huggingface_hub>=0.24.5) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anumkhan/venv/lib/python3.9/site-packages (from rich>=12.3.0->typer->huggingface_hub>=0.24.5) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/anumkhan/venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer->huggingface_hub>=0.24.5) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run once to install dependencies\n",
    "%pip install openai datasets pandas matplotlib -q\n",
    "%pip install -U \"huggingface_hub>=0.24.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, json, time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from LLM_utils import (\n",
    "    LLMConfig, LLMRequest, SimpleDiskCache, \n",
    "    generate, self_consistency_samples, simple_majority_vote,\n",
    "    build_finqa_prompt, parse_json_answer, append_jsonl, DEFAULT_SYSTEM,\n",
    "    make_delimited_prompt, with_retries\n",
    ")\n",
    "\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-config",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Config\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      3\u001b[0m load_dotenv()  \u001b[38;5;66;03m# loads .env into os.environ automatically\u001b[39;00m\n\u001b[1;32m      5\u001b[0m HF_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # loads .env into os.environ automatically\n",
    "\n",
    "HF_API_KEY = os.getenv('HF_API_KEY')  \n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "MODELS: Dict[str, LLMConfig] = {\n",
    "    # Free HuggingFace Inference API models\n",
    "    'mistral-7b':  LLMConfig(provider='huggingface', model='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.2, max_tokens=512),\n",
    "    'llama-3':     LLMConfig(provider='huggingface', model='meta-llama/Meta-Llama-3-8B-Instruct', temperature=0.2, max_tokens=512),\n",
    "    'mock':        LLMConfig(provider='mock',        model='mock', temperature=0.2, max_tokens=512),\n",
    "}\n",
    "\n",
    "SELECTED_MODELS = ['mistral-7b', 'mock']  # ← swap / add models here\n",
    "MAX_ROWS        = 10    # number of FinQA examples to evaluate\n",
    "N_SC_SAMPLES    = 5     # self-consistency samples per example\n",
    "RESULTS_PATH    = 'runs/exploration_results.jsonl'\n",
    "CACHE_PATH      = 'runs/llm_cache.jsonl'\n",
    "\n",
    "cache = SimpleDiskCache(CACHE_PATH)\n",
    "print('Config ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-data-header",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-data",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_ROWS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rows\n\u001b[0;32m---> 23\u001b[0m rows \u001b[38;5;241m=\u001b[39m load_data(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, max_rows\u001b[38;5;241m=\u001b[39m\u001b[43mMAX_ROWS\u001b[49m)\n\u001b[1;32m     24\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgold_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_ROWS' is not defined"
     ]
    }
   ],
   "source": [
    "def load_data(split: str = 'test', max_rows: int = 10) -> List[Dict]:\n",
    "    path = f'data/finQA/{split}.json' # Load data from local finQA dataset\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        raw = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for i, ex in enumerate(raw[:max_rows]):\n",
    "        pre   = ' '.join(ex.get('pre_text',  []) or [])\n",
    "        post  = ' '.join(ex.get('post_text', []) or [])\n",
    "        table = '\\n'.join(' | '.join(str(c) for c in r) for r in (ex.get('table') or []))\n",
    "        rows.append({\n",
    "            'id':          ex.get('id', f'{split}_{i}'),\n",
    "            'split':       split,\n",
    "            'question':    ex['qa']['question'],\n",
    "            'context':     f'{pre}\\n\\nTable:\\n{table}\\n\\n{post}'.strip(),\n",
    "            'gold_answer': str(ex['qa']['answer']),\n",
    "        })\n",
    "\n",
    "    print(f'Loaded {len(rows)} rows from {path}')\n",
    "    return rows\n",
    "\n",
    "rows = load_data(split='test', max_rows=MAX_ROWS)\n",
    "pd.DataFrame(rows)[['id', 'question', 'gold_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-uq-header",
   "metadata": {},
   "source": [
    "## 2. UQ Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-uq-sc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Consistency defined\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Self-Consistency\n",
    "\"\"\"\n",
    "Core idea: ask the model the same question N times and see if it keeps giving the same answer. \n",
    "High agreement = high confidence. \n",
    "Disagreement = likely hallucinating.\n",
    "\"\"\"\n",
    "\n",
    "def uq_self_consistency(system, user, cfg, n=5, cache=None):\n",
    "    # return agreement ratio as confidence\n",
    "    samples = self_consistency_samples(system, user, cfg, n=n, cache=cache)\n",
    "    answers = [str(parse_json_answer(s.text).get('final_answer', '')).strip() for s in samples]\n",
    "    majority, counts = simple_majority_vote(answers)\n",
    "    return {\n",
    "        'method':          'self_consistency',\n",
    "        'confidence':      round(counts.get(majority, 0) / max(len(answers), 1), 4),\n",
    "        'majority_answer': majority,\n",
    "        'vote_counts':     counts,\n",
    "    }\n",
    "\n",
    "print('Self-Consistency defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfce2df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Quick test — uses mock provider so no API calls\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_cfg    \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m test_row    \u001b[38;5;241m=\u001b[39m rows[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m test_user   \u001b[38;5;241m=\u001b[39m build_finqa_prompt(test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick test — uses mock provider so no API calls\n",
    "test_cfg    = MODELS['mock']\n",
    "test_row    = rows[0]\n",
    "test_user   = build_finqa_prompt(test_row['context'], test_row['question'])\n",
    "test_result = uq_self_consistency(DEFAULT_SYSTEM, test_user, test_cfg, n=3, cache=None)\n",
    "\n",
    "print(f\"Method:     {test_result['method']}\")\n",
    "print(f\"Confidence: {test_result['confidence']}\")\n",
    "print(f\"Answer:     {test_result['majority_answer']}\")\n",
    "print(f\"Votes:      {test_result['vote_counts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-uq-lpe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogProb Entropy defined\n"
     ]
    }
   ],
   "source": [
    "def uq_logprob_entropy(system, user, cfg, cache=None):\n",
    "    \"\"\"\n",
    "    Core idea: Instead of asking the model multiple times, we look inside a single response at \n",
    "    how certain the model was about each word it chose. \n",
    "    High certainty per word = high confidence.\n",
    "    \"\"\"\n",
    "    if cfg.provider != 'openai':\n",
    "        return {'method': 'logprob_entropy', 'confidence': None, 'mean_entropy': None}\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "\n",
    "        def _call():\n",
    "            return client.chat.completions.create(\n",
    "                model=cfg.model,\n",
    "                messages=[{'role': 'system', 'content': system}, {'role': 'user', 'content': user}],\n",
    "                temperature=0.0, max_tokens=cfg.max_tokens, logprobs=True, top_logprobs=5,\n",
    "            )\n",
    "\n",
    "        resp    = with_retries(_call, max_retries=cfg.max_retries)  # from LLM_utils\n",
    "        lp_data = resp.choices[0].logprobs.content or []\n",
    "        entropies = []\n",
    "        for tok in lp_data:\n",
    "            probs = [math.exp(t.logprob) for t in (tok.top_logprobs or [])]\n",
    "            if probs:\n",
    "                total = sum(probs)\n",
    "                probs = [p / total for p in probs]\n",
    "                entropies.append(-sum(p * math.log(p + 1e-12) for p in probs))\n",
    "        mean_h = sum(entropies) / len(entropies) if entropies else None\n",
    "        return {\n",
    "            'method':       'logprob_entropy',\n",
    "            'mean_entropy': round(mean_h, 6) if mean_h else None,\n",
    "            'confidence':   round(1.0 - mean_h / math.log(5), 4) if mean_h else None,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'method': 'logprob_entropy', 'confidence': None, 'mean_entropy': None, 'error': str(e)}\n",
    "\n",
    "print('LogProb Entropy defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc770620",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test — logprob entropy returns None for non-openai providers (expected)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m test_row \u001b[38;5;241m=\u001b[39m rows[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m test_user \u001b[38;5;241m=\u001b[39m build_finqa_prompt(test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "# Test — logprob entropy returns None for non-openai providers (expected)\n",
    "test_cfg = MODELS['mock']\n",
    "test_row = rows[0]\n",
    "test_user = build_finqa_prompt(test_row['context'], test_row['question'])\n",
    "\n",
    "test_result = uq_logprob_entropy(DEFAULT_SYSTEM, test_user, test_cfg)\n",
    "\n",
    "print(f\"Method:       {test_result['method']}\")\n",
    "print(f\"Confidence:   {test_result['confidence']}\")   # expect None — mock isn't openai\n",
    "print(f\"Mean Entropy: {test_result['mean_entropy']}\") # expect None\n",
    "print(f\"Note: returns None for non-OpenAI providers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-uq-vc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbalized Confidence defined\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Verbalized Confidence\n",
    "def uq_verbalized_confidence(context, question, cfg, cache=None):\n",
    "    \"\"\"Core idea: just ask the model how confident it is. \"\"\"\n",
    "    task = (\n",
    "        'Solve the financial question step-by-step.\\n'\n",
    "        'Output ONLY this JSON on the last line (no extra keys):\\n'\n",
    "        '{\"final_answer\": \"...\", \"confidence_pct\": <0-100>, \"reasoning\": \"...\"}'\n",
    "    )\n",
    "    user_prompt = make_delimited_prompt(task, f'CONTEXT:\\n{context}\\n\\nQUESTION:\\n{question}')\n",
    "    req  = LLMRequest(system='You are a careful financial reasoning assistant.',\n",
    "                      user=user_prompt, meta={'uq': 'verbalized'}, config=cfg)\n",
    "    resp = generate(req, cache=cache)\n",
    "    parsed   = parse_json_answer(resp.text)\n",
    "    conf_raw = parsed.get('confidence_pct')\n",
    "    return {\n",
    "        'method':       'verbalized_confidence',\n",
    "        'confidence':   round(float(conf_raw) / 100.0, 4) if conf_raw is not None else None,\n",
    "        'final_answer': str(parsed.get('final_answer', '')).strip(),\n",
    "    }\n",
    "\n",
    "print('Verbalized Confidence defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1987ddee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test — verbalized confidence\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_cfg  \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m test_row  \u001b[38;5;241m=\u001b[39m rows[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m test_result \u001b[38;5;241m=\u001b[39m uq_verbalized_confidence(test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], test_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], test_cfg, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "# Test — verbalized confidence\n",
    "test_cfg  = MODELS['mock']\n",
    "test_row  = rows[0]\n",
    "\n",
    "test_result = uq_verbalized_confidence(test_row['context'], test_row['question'], test_cfg, cache=None)\n",
    "\n",
    "print(f\"Method:       {test_result['method']}\")\n",
    "print(f\"Confidence:   {test_result['confidence']}\")    # None — mock returns plain string, not valid JSON with confidence_pct\n",
    "print(f\"Final Answer: {test_result['final_answer']}\")  # None — same reason\n",
    "print(f\"Note: mock doesn't return confidence_pct field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pipeline-header",
   "metadata": {},
   "source": [
    "## 3. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-correctness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline helpers defined\n"
     ]
    }
   ],
   "source": [
    "def is_correct(predicted: str, gold: str) -> bool:\n",
    "    # Fuzzy match: strips white space,symbols,lowercase then compares .\n",
    "    def norm(s):\n",
    "        return re.sub(r'[\\s\\$,%]+', '', s.lower().strip())\n",
    "    p, g = norm(predicted), norm(gold)\n",
    "    return p == g or g in p or p in g\n",
    "\n",
    "def run_example(row, model_name, cfg, n_sc=5, cache=None):\n",
    "    #Run all three UQ methods on one FinQA example.\n",
    "    user_prompt = build_finqa_prompt(row['context'], row['question'])\n",
    "\n",
    "    # Baseline greedy answer\n",
    "    baseline = generate(\n",
    "        LLMRequest(system=DEFAULT_SYSTEM, user=user_prompt,\n",
    "                   meta={'id': row['id'], 'model': model_name}, config=cfg),\n",
    "        cache=cache\n",
    "    )\n",
    "    baseline_answer = str(parse_json_answer(baseline.text).get('final_answer', '')).strip()\n",
    "\n",
    "    sc  = uq_self_consistency(DEFAULT_SYSTEM, user_prompt, cfg, n=n_sc, cache=cache)\n",
    "    lpe = uq_logprob_entropy(DEFAULT_SYSTEM, user_prompt, cfg, cache=cache)\n",
    "    vc  = uq_verbalized_confidence(row['context'], row['question'], cfg, cache=cache)\n",
    "\n",
    "    return {\n",
    "        'id': row['id'], 'model': model_name,\n",
    "        'question': row['question'], 'gold': row['gold_answer'],\n",
    "        'predicted': baseline_answer,\n",
    "        'correct': is_correct(baseline_answer, row['gold_answer']),\n",
    "        'sc_confidence':  sc['confidence'],\n",
    "        'lpe_confidence': lpe.get('confidence'),\n",
    "        'vc_confidence':  vc.get('confidence'),\n",
    "        'vc_answer':      vc.get('final_answer'),\n",
    "    }\n",
    "\n",
    "print('Pipeline helpers defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-run",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SELECTED_MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mSELECTED_MODELS\u001b[49m:\n\u001b[1;32m      4\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m MODELS[model_name]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples) ===\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SELECTED_MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in SELECTED_MODELS:\n",
    "    cfg = MODELS[model_name]\n",
    "    print(f'\\n=== {model_name} ({len(rows)} examples) ===')\n",
    "    for row in rows:\n",
    "        try:\n",
    "            r = run_example(row, model_name, cfg, n_sc=N_SC_SAMPLES, cache=cache)\n",
    "            results.append(r)\n",
    "            append_jsonl(RESULTS_PATH, r)\n",
    "            status = '✓' if r['correct'] else '✗'\n",
    "            print(f\"  {status} [{row['id']}] predicted={r['predicted']!r}  gold={row['gold_answer']!r}  sc={r['sc_confidence']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] {row['id']}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(f'\\nDone. {len(df)} results saved to {RESULTS_PATH}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-analysis-header",
   "metadata": {},
   "source": [
    "## 4. Calibration Analysis\n",
    "Key hypothesis: **high confidence → more likely correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-calibration-table",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m rows_summary \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, label \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[0;32m----> 6\u001b[0m     sub \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[col])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub\u001b[38;5;241m.\u001b[39mempty: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     hi \u001b[38;5;241m=\u001b[39m sub[sub[col] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESHOLD]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.7\n",
    "methods = [('sc_confidence', 'Self-Consistency'), ('lpe_confidence', 'LogProb Entropy'), ('vc_confidence', 'Verbalized Conf')]\n",
    "\n",
    "rows_summary = []\n",
    "for col, label in methods:\n",
    "    sub = df.dropna(subset=[col])\n",
    "    if sub.empty: continue\n",
    "    hi = sub[sub[col] >= THRESHOLD]\n",
    "    lo = sub[sub[col] <  THRESHOLD]\n",
    "    rows_summary.append({\n",
    "        'Method': label,\n",
    "        'High-conf n': len(hi), 'High-conf acc': f\"{hi['correct'].mean():.0%}\" if len(hi) else 'N/A',\n",
    "        'Low-conf n':  len(lo), 'Low-conf acc':  f\"{lo['correct'].mean():.0%}\" if len(lo) else 'N/A',\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows_summary).set_index('Method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-calibration-plot",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence vs Correctness by UQ Method\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax, (col, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes, methods):\n\u001b[0;32m----> 5\u001b[0m     sub \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[col])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m      7\u001b[0m         ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(no data)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "fig.suptitle('Confidence vs Correctness by UQ Method', fontsize=13)\n",
    "\n",
    "for ax, (col, label) in zip(axes, methods):\n",
    "    sub = df.dropna(subset=[col])\n",
    "    if sub.empty:\n",
    "        ax.set_title(f'{label}\\n(no data)')\n",
    "        continue\n",
    "    # Bin into 5 buckets, plot mean accuracy per bucket\n",
    "    sub = sub.copy()\n",
    "    sub['bin'] = pd.cut(sub[col], bins=5)\n",
    "    grouped = sub.groupby('bin', observed=True)['correct'].mean()\n",
    "    grouped.plot(kind='bar', ax=ax, color='steelblue', edgecolor='white')\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('Confidence bucket')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('runs/calibration_plot.png', dpi=120)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS7324-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
